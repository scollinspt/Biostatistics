--- 
title: "Biostatistics for Clinical Research"
subtitle: "Theory and Applications in R"
author: "Sean Collins"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output:
  bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: scollinspt/Biostatistics
description: "This is an open educational resource (OER) book for Biostatistics for Clinical Research: Theory & Applications in R using the bookdown package in RStudio. The output format for this example is bookdown::gitbook."

---

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

# Preface {-#preface}

This version has been written in Scrivener, exported as plain text as a single index.Rmd file and then used to build the book. If this worked, then it’s an entirely new workflow for writing and self publishing books that takes advantage of the organizing and writing features of Scrivener, and the computational analysis and publishing features of R, Rmarkdown and Bookdown.

At this point I’ve created a special compile format in Scrivener that puts an empty line between each folder and file. Each folder functions as a “Part” of the book, and each text file (in Scrivener) as a chapter in that part. However, Scrivener compiles one Index file which may make editorial contributions more challenging since the entire book is in one large file on Github and in bookdown. But that is something I’m willing to live with since the benefits of organizing, creating and writing in Scrivener for the project are well worthwhile.

Biostatistics for Clinical Research: Theory and Applications in R is a book for the Biostatistics sequence of courses (1 & 2) at the University of Jamestown PhD in Clinical Research program. The book teaches and utilizes examples with the open source computational platform R  ( https://cran.r-project.org/). There is an emphasis and equal distribution of theory and application through all chapters. There is an underlying emphasis on performing all applications utilizing reproducible research approaches (programming with sufficient commentary) and tools (GitHub, Figshare, Open Science Framework, etc) throughout the book.

The book covers the theoretical foundations of biostatistics and the associated computational approaches of exploratory, descriptive and inferential biostatistical methods for the analysis of data in clinical research (observational and experimental). These methods are based on probability theory and include assessing the impact of chance and variability on the interpretation of research findings. Topics include probability theory, measurement theory, descriptive and exploratory analysis, analysis of assumptions and visualization; hypothesis testing; methods of comparison of discrete and continuous data including t-test, correlation, regression, and general linear models (including ANOVA). Applications and examples utilize the R statistical programming language to apply theoretical topics with real world data.



# Introduction {-#intro}

Under development

# Part I {-#part1}

## Tentative ToC

### Part One (Biostatistics I)

1. The role of biostatistics in clinical research
2. Programming Concepts in R
3. Probability & Statistical Inference
4. Measurement
5. Tidying for Tidy Data
6. Transforming for Transformed Data
7. Descriptive Statistics
8. Exploratory Analysis

# The role of biostatistics in clinical research

Under development

From clinical inquiry book - not sure where this may apply in this text; maybe as a review in an appendix since they should know this (it is entry level material for most clinicians)

## Preliminaries

### Contingency Table

|                | $D$            | $\neg D$                      |
|:--------------:|:-------------:|:-----------------------:|
| $S$             | True Positive (TP) (a) | False Positive (FP) (b)|
| $\neg S$             | False Negative (FN) (c) | True Negative (TN) (d) |

### Sensitivity / Specificity

Sensitivity: $P(S|D)=\dfrac{a}{a+c}$ (Rate of True Positives)

Specificity: $P(\neg S|\neg D)=\dfrac{d}{b+d}$ (Rate of True Negatives)

1 - Sensitivity: $P(\neg S|D)=\dfrac{c}{a+c}$ (Rate of False Negatives)

1 - Specificity: $P(S|\neg D)=\dfrac{b}{b+d}$ (Rate of False Positives)

### Positive Likelihood Ratio

$+LR=\dfrac{Sensitivity}{1-Specificity}$

$+LR=\dfrac{P(S|D)}{P(S|\neg D)}$

$+LR= \dfrac{P(TP)}{P(FP)}$

$+LR= \dfrac{a(b+d)}{b(a+c)}$

### Negative Likelihood Ratio

$-LR=\dfrac{1-Sensitivity}{Specificity}$

$-LR=\dfrac{P(\neg S|D)}{P(\neg S|\neg D)}$

$-LR= \dfrac{P(FN)}{P(TN)}$

$-LR= \dfrac{c(b+d)}{d(a+c)}$ 

## Bayes Formula

$P(D|S)=\dfrac{P(S|D)\cdot P(D)}{P(S)}$

The $P(D)$ and $P(S)$ are the "priors" - or "baseline" probabilities of the disease and the sign

### Alternative format

$P(\neg D|\neg S)=\dfrac{P(\neg S|\neg D)\cdot P(\neg D)}{P(\neg S)}$

The $P(\neg D)$ and $P(\neg S)$ are the "priors" - or "baseline" probabilities of not having the disease or the sign




# Programming Concepts in R

Under development


# Probability & Statistical Inference

Under development - current text copied from another book in development for DPT students called "Clinical Inquiry"

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Probability introduction

### State space (sample space)

An event space is often denoted by sigma ($\Sigma$) and contains all sets of outcomes. 

A sample space of an experiment is denoted by omega ($\Omega$) and contains all possible outcomes.

We will usually be dealing with $\Omega$, but for something like a 6 sided dice we can use $\Sigma$.

If $E$ defines an event, (say rolling a 6 on a dice), then {1, 2, 3, 4, 5, 6} is the event space (all sets of outcomes)

$P(E) = \frac{E}{\Sigma}$

$P(rolling \space a\space 6) = \frac{rolling \space a\space 6}{6} = \frac{1}{6}$

You expect a 6 about $\frac{1}{6}$. What is an unexpected outcome?

### Probability is bound between 0 and 1

$0 \le P(E) \le 1$

### Certainty and uncertainty

Certainty includes $P(E) = 0$ and $P(E) = 1$

Therefore the probability of an uncertain event is $0 < P(E) < 1$ (particular)

Therefore the probability of all uncertain events are $0 < P(E) < 1$ (universal)

### Connection to deductive logic

If $E$ is $TRUE$, then $P(E) = 1$

If $E$ is $FALSE$, then $P(E) = 0$

### Using Sets as "Probability Spaces"

Recall:

- $E \subseteq F$ is that E is a "subset" of F
- $E \cap F$ is set intersection and is similar to logical "and" ($\land$)
- $E \cup F$ is set union and is similar to logical "or" ($\lor$)

If $E \subseteq F$, then $P(E) \le P(F)$

If $E \cap F$, then $P(E \lor F) = P(E)+P(F)$

### Conditional probability

$P(E \mid F)$ is the $P(E)$ "given that" $P(F) = 1$ or you could say $F$ is $TRUE$

Therefore:

If $E \subseteq F$, then $P(F \mid E) = 1$

If $E \cap F = 0$, then $P(E \mid F) = 0$

### Causation connections

If $E$ causes $F$ we can use the notation $E \rightarrow F$;

Then it is true that $P(F \mid E) \ge P(F \mid \neg E)$ (note that $\neg$ means "not")

This is the notation for Hill's criteria, "strength of association" and is consistent with the statement: "causation implies correlation", but notice that it is inconsistent with the statement "correlation implies causation" (as you have learned, correlation does not imply causation).

## Notes and thoughts on Chapter 3: Probability in the clinical encounter 

Notes and thoughts on Chapter 3 from the book: (Anjum, R. L., Copeland, S., & Rocca, E. (2020). Rethinking causality, complexity and evidence for the unique patient: a CauseHealth Resource for healthcare professionals and the clinical encounter (p. 241). Springer Nature.)[https://link.springer.com/book/10.1007%2F978-3-030-41239-5]

### 3.1 Uncertainty and Probability in the Single Case

A goal of this book - and indeed of all clinical inquiry - is to consider the probability that intervention $X$ will work this time for this patient

Note that the probability that $X$ "will work" this time for this patient is a conditional probability (let's take $P(X)$ to be the probability that intervention $X$ works).

Therefore, $P(X \mid p_i)$, is the probability that $X$ will occur (and $X$ is that intervention $X$ will work) given $p_i$ (note that I'm using $p_i$ as notation for "this time for this patient").

For one moment - consider what it means to say an intervention works? It means that an outcome has been achieved. If you have a headache, and you take an Tylenol capsule, you consider that it works if your headache goes away. That is an outcome indicating the intervention worked.

We can also break $X$ into a conditional probability, since $P(X)$ is the probability that intervention $I$ is effective; and since $I$ being effective depends on $O$, the outcome:

$P(X) = P(O \mid I)$ (the probability of $X$ being effective is the probability of $O$ given $I$)

Notice that this conditional probability $P(O \mid I)$ is equivalent to the causal claim: $I \rightarrow O$

#### Where does this probability come from? What does it represent? What do we mean by it?


### 3.2 Probability from Statistics: Frequentism

Frequentism is the probability that you're familiar with from statistics. It is considered "objective" in that it is based on measurements of observations. These probabilities are often estimated from samples in an attempt to understand something about the population. This is the process of statistical inference we'll talk about soon, and is "induction" as we've already discussed.

The assumption is that as the sample size ($n$) gets larger we are more confident in the estimate:

As $n_{sample}$ approaches $n_{population}$ we are more confident in the estimate of the population (and thus maybe "universal") probability.

We'll talk a lot more next week about confidence in these estimates when we discuss statistical inference using "confidence intervals".

Note that estimates are both variable and uncertain. Variability is part of their behavior. In fact, variability says something about the events.

#### 3.2.1 Evidence based approaches: 

Usually rely on estimates described from samples. The issue, and challenge, is applying these estimates to apatient that was not part of that sample.

#### 3.2.2 Randomization, Inclusion and Exclusion Criteria in population (sample) trials:

Used to reduce bias.

Bias associated with unknown confounders (randomization)

Bias associated with known confounders (inclusion and exclusion criteria)

#### Internal and external validity of causal claims from RCTs:

Causal claims from RCTs are statements of whether some intervention is effective ($X$).

**Internal Validity**

If $X$ is determined to be $TRUE$ for a sample, we can consider $X \subseteq S$ which means $X$ as a characteristic is one of the characteristics of the sample $S$.

Threats to internal validity impact whether the study actually demonstrated what they claim to have demonstrated.

**External Validity**

Then we need to consider whether the sample is a subset of the population (whether the characteristics of the sample are true for the population: $S \subseteq P$

Threats to external validity impact whether the findings of the study in this sample, apply to the population (related to statistical inference and induction)

Overall: $(X \subseteq S) \land (S \subseteq P) \Rightarrow (X \subseteq P)$

Which means that if X is true for the sample, and the sample reflects the population, then X is true for the population (transitivity).

The mission of this book, and the project from which is comes (CauseHealth), and my work for the past 17 years or so, has been dealing with the fact that the patient you're working with ($p_i$) is not in the sample, and not necessarily in the population.

Just because: $(X \subseteq S) \land (S \subseteq P) \Rightarrow (X \subseteq P)$ is true (and that is usually uncertain)


It does not mean that:

$(X \subseteq P) \land (p_i \subseteq P) \Rightarrow (X \subseteq p_i)$

In fact:

$(X \subseteq P) \land (p_i \subseteq P) \nRightarrow (X \subseteq p_i)$


### 3.3 Probability as Degree of Belief - Subjective Credence

Three things: 
First, don't conflate conditional probabilities with "subjective"
Second, don't conflate Bayesian probabilities or inference with "subjective"
Third, don't make as big a deal of "objective" and "subjective" probabilities as they do in this chapter.

As you will come to appreciate, all objective probabilities are obtained with some subjectivity; and all subjective probabilities are founded in some sort of objectivity.

You'll also come to appreciate that all causal claims can be considered as conditional probability; and since all clinical practice is based on causal claims, then all clinical practice is based on conditional probabilities. Every question you ask, every action you take is because whatever you know "right now" is adjusted based on "what you have just learned." Meaning, you're always adjusting your belief / understanding / knowledge based on new information - - which is the same thing as saying you're always using conditional probabilities.


#### 3.3.1 Updating belief - as stated above, absolutely unavoidable if you want to be a good clinician

#### 3.3.2 Understanding the basic Bayesian formula - to be covered in Chapter 7 

#### 3.3.3  Uncertainty as a lack of knowledge

Here I believe they are overstating the difference between ontology and epistemology. 

There is variability in an event $E$, we try to figure out why, but whether it is ontological or epistemological may not be reconciled; this does not change the value of knowing what we can find out.

### 3.4 Probability as Dispositional and Intrinsic Properties

Provides some language - I'm honestly not yet sure how it benefits the overall goal.

For example, I think we've always thought of probabilities are reflection the "propensity" of an event. Some of that is "intrinsic" to the characteristics of the event itself, some of it is due to variability of other factors.

Once again we see that the purpose of the book includes a conditional probability: "The individual propensities of a single patient, treatment or context are given by it's unique combination of dispositions and the dispositions' degree of tendency (propensity) toward particular outcomes in that individual case."

$P((O \mid I) \mid p_i)$

The probability of an outcome given the intervention, given this time for this patient.

### 3.5 Propensities and the Clinic

Useful with consideration to the notes above. How usual is yet to be determined (at least in my opinion).

## Statistical Inference (Induction)

This chapter describes the use Confidence Intervals as a tool for making statistical inferences. Statistical inferences use probability to consider how effective inductive inferences from a sample are at providing an an estimate of a characteristic (often referred to as a parameter) in a population. Samples are collections of individual (particular) observations and a population represents a universal (or general) characteristic. Estimates from a sample are called statistics, whereas estimates from a population are parameters. 

Two common parameters that we attempt to estimate are proportions (percentage of some characteristic) and means (mathematical average). The actual numerical value of a population proportion or mean would rarely be known.

In order to estimate the population proportion or mean we calculate a sample proportion or mean from a sample. The value of the sample mean is then used to estimate an unknown population mean.

Since we know that there is error in our estimate, the question becomes how much error? The amount of error is related to the size of the sample. 

## Confidence Intervals (CI)

A confidence interval provides an interval around a sample estimate that contains the population parameter with a given probability. For example, a 95% CI is an interval that is expected to contain the true population parameter 95% of the time.

If the mean height of a sample of students is 69 inches, and the 95% CI = [66, 72], then the population parameter (mean height) has a probability of 0.95 to between 66 and 72 inches.

Another interpretation is that if we were to randomly sample 100 samples of the same size from the same population, 95% of the sample means would fall within the ranage of the 95% CI = [66, 72].

### General equations

$sample \space estimate = population \space parameter + random \space error$

$95\%CI=sample \space estimate \pm z \times \space standard \space error$

Where $z$ is a multiplier that comes from the normal curve. For a 95% CI $z$ is often taken to be 1.96 (or 2 more conservatively). Another option is to use the $t$ distribution (flatter and wider than the normal curve) which is recommended for samples of less than 30.

### CI for a Proportion
$\sqrt{\frac{}{}}$
$95\%CI=sample \space proportion \pm z \times \sqrt{\frac{sample \space proportion(1-sample \space proportion)}{n}}$

Note the Standard Error of a sample proportion is:

$Standard \space Error \space of \space sample \space proportion=\sqrt{\frac{sample \space proportion(1-sample \space proportion)}{n}}$

### CI for a Mean

$95\%CI=sample \space mean \pm z \times \frac{standard \space deviation}{\sqrt{n}}$

Note the Standard Error of the Mean is:

$Standard \space Error \space of \space the \space Mean=\frac{standard \space deviation}{\sqrt{n}}$

### CI to evaluate differences

Standard Error (SE) of a Difference:

$SE \space for \space a \space Difference=\sqrt{(SE_1)^2 +(SE_2)^2}$

Note: $SE_1$ is the SE for group 1; and $SE_2$ is the SE for group 2.

$95\%CI=difference \space between \space samples \pm z \times (SE \space for \space a \space Difference)$



# Measurement

Under development

# Tidying for Tidy Data

Under development

# Transforming for Transformed Data

Under development

# Descriptive Statistics

Under development

# Exploratory Analysis


Under development

# Part II  {-#part2}

## Tentative Contents

9. Computational Approaches to Statistical Inference
10. Methods for Statistical Modeling
11. Building Statistical Models
12. Evaluating & Interpreting Statistical Models
13. Presentation & Dissemination

# Computational Approaches to Statistical Inference

Under development

# Methods for Statistical Modeling

Under development

# Evaluating & Interpreting Statistical Models

Under development

# Presentation & Dissemination

Under development